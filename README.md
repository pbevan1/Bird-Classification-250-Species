# Bird-Classification-250-Species (96.16%)

There are quite a large number of images and so rather than directly loading them into memory, the Keras ImageDataGenerator was used, which allowed batched loading and also allowed easy scaling for passing arrays as values between 0 and 1 into the model. Transfer learning was used to harness the power of the EfficientNetB7 pretrained on the massive ImageNet dataset. P. Huigol, (2020) suggested that the B7 version of EfficientNet would perhaps be one of the most powerful image classifiers available, and this is the inspiration behind going with this model. Following this frozen pretrained model, several trainable dense layers were added which allow the model to fit to the given data. I have seen examples of dense layers being added to a frozen efficientNetB0 working well for image classification so I was confident that this approach would yield decent results.
Batch normalisation was added after each dense layer with the hope of stabilising the learning process and reducing the training time since the model is quite deep and there are many millions of parameters, which could lead to overfitting and excessive training time. Dropout was also added as a further regularisation technique to reduce overfitting and hopefully allow the model to generalise better to the test set. Image augmentation (horizontal flipping, 25 degree random rotation and random brightness) was experimented with, but only seemed to decrease accuracy, and so was scrapped.
Keras tuner was used for some of the hyperparameter selection, namely to choose how many dense layers with batch normalisation and dropout to use (searched between 1 and 3), how many units to have in each of these layers (searched between 512 and 2048), as well as to choose the optimal learning rate. The loss function was chosen as sparse categorical cross entropy, since there is a large number of mutually exclusive classes. The tuner chose one of the simpler models, but I am slightly curious as to whether this is more down to the number of epochs used during tuning. Perhaps the simpler models reached a decent accuracy within the 3 epochs, while the more complex models did not reach their peak during this time. This is something I will play with when I have more time, but for this project I didnâ€™t have chance to re-tune as it took up a considerable number of GPU hours. With this in mind, the 2nd best model from Keras tuner was chosen (see code for exact hyperparameters), as the validation accuracy was almost the same, but the model is deeper and hopefully would surpass the other model after longer training. With more time/resources the dropout probability would also have been tuned, but for this project the standard 0.5 was used as set out in the original paper by Srivastava et al. (2014). Early stopping was implemented after I noticed the validation accuracy was oscillating between epochs, and it would be difficult to manually catch the top. This allowed another 1% extra accuracy to be gained from the model. Interestingly, the validation accuracy was consistently higher than the training accuracy, perhaps the validation data contained less outlying examples than the training data
The final trained model achieved a classification accuracy of 96.16%, with a precision of 0.9676 and recall of 0.9616. A confusion matrix/heatmap was created based on the prediction of bird species in the test set (1250 images). The colour scale on the side shows the colours that correspond to the number of predictions for each truth/prediction pair. Ideally, everywhere would be completely black except for the diagonal (this represents ground truth and prediction matching). The reality in this case is not far from this, with only a few classification mistakes dotted around (slightly lighter blue dots). It looks as though one species of bird was misclassified as the same wrong species twice (maroon dots), likely meaning that the model is getting confused between the two species due to some similarity between them.
